# Vietnam History Chat Datasets (VI & EN)

Synthetic, instruction-style **chat datasets** about **Vietnamese history (905â€“2025)** for training and evaluating reasoning-capable chat models (GPT-OSS/Harmony, TRL, etc.).  
Each sample follows a ShareGPT/ChatML-like `messages` schema with optional assistant reasoning in an `analysis` channel and a concise reply in `final`.

> If this project helps you, please **â­ star** the repo and **â¤ï¸ Like** the dataset on Hugging Face!

---

## âš ï¸ Disclaimer

**Dataset collection by AI from public source so it can make mistakes.**  
This dataset was collected/generated by AI from public sources and may contain errors or omissions. Please verify and curate before production use.

*Tiáº¿ng Viá»‡t:* **Bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c thu tháº­p/táº¡o bá»Ÿi AI tá»« nguá»“n cÃ´ng khai nÃªn cÃ³ thá»ƒ cÃ³ sai sÃ³t.** HÃ£y kiá»ƒm chá»©ng trÆ°á»›c khi dÃ¹ng cho má»¥c Ä‘Ã­ch sáº£n xuáº¥t.

---

## ğŸ“š Available datasets (Hugging Face)

- **500K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-500K-Vi  
- **500K (EN):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-500K-En  
- **200K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-200K-Vi  
- **200K (EN):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-200K-EN  
- **100K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-100K_Vi  
- **100K (EN):** https://huggingface.co/datasets/minhxthanh/VietNam-History-100K_EN  
- **50K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-50K  
- **25K (VI):** https://huggingface.co/datasets/minhxthanh/VietNam-History-25K  
- **15K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-15k

> See the author profile for activity and updates: https://huggingface.co/minhxthanh. :contentReference[oaicite:1]{index=1}

---

## ğŸ§  Content coverage

From **KhÃºc/NgÃ´ (905)** â†’ **Äinh â€“ Tiá»n LÃª â€“ LÃ½ â€“ Tráº§n â€“ Há»“ â€“ Minh thuá»™c â€“ LÃª sÆ¡ â€“ Máº¡c â€“ LÃª trung hÆ°ng (Trá»‹nhâ€“Nguyá»…n) â€“ TÃ¢y SÆ¡n â€“ Nguyá»…n â€“ thá»i PhÃ¡p thuá»™c â€“ 1945â€“1975 â€“ Äá»•i Má»›i â€“ há»™i nháº­p â€“ Ä‘Æ°Æ¡ng Ä‘áº¡i (Ä‘áº¿n 2025)**.  
Prompt styles include **year-based**, **event summaries**, **person-focused**, **why/how causality**, and **context â†’ developments â†’ outcome**.

---

## ğŸ—‚ï¸ Data schema

Each row is a JSON object with a single `messages` list:

```json
{
  "messages": [
    {"role": "system", "content": "You are a Vietnam history assistant. Answer concisely."},
    {"role": "user", "content": "What happened in 938?"},
    {"role": "assistant", "channel": "analysis", "content": "Identify the key event..."},
    {"role": "assistant", "channel": "final", "content": "In 938, the Battle of Báº¡ch Äáº±ng... ended Chinese rule."}
  ]
}
````

* `role` âˆˆ {`system`, `user`, `assistant`}.
* `content`: string.
* Optional `channel` for assistant:

  * `analysis` â†’ chain-of-thought / reasoning (present in most samples).
  * `final` â†’ short answer shown to the user.
* A minority of records are **final-only** (no `analysis`) to balance concise vs. reasoning behavior.

### VI example

```json
{
  "messages": [
    {"role":"system","content":"Báº¡n lÃ  trá»£ lÃ½ lá»‹ch sá»­ Viá»‡t Nam."},
    {"role":"user","content":"TÃ³m táº¯t Tráº­n Báº¡ch Äáº±ng (1288)."},
    {"role":"assistant","channel":"analysis","content":"XÃ¡c Ä‘á»‹nh bá»‘i cáº£nh khÃ¡ng NguyÃªn láº§n 3..."},
    {"role":"assistant","channel":"final","content":"NÄƒm 1288, Tráº§n HÆ°ng Äáº¡o nhá»­ Ä‘á»‹ch vÃ o bÃ£i cá»c trÃªn sÃ´ng Báº¡ch Äáº±ng vÃ  tiÃªu diá»‡t thá»§y quÃ¢n NguyÃªn."}
  ]
}
```

---

## ğŸš€ Quick start (ğŸ¤— Datasets)

```python
from datasets import load_dataset

ds = load_dataset("minhxthanh/Vietnam-History-500K-Vi", split="train")
print(ds[0]["messages"][0]["role"], ":", ds[0]["messages"][0]["content"])
```

*Tip:* Large splits (e.g., 500K) may stream/convert to Parquet on first load.

---

## ğŸ¦¥ Harmony / GPT-OSS (Unsloth) workflow

These datasets map cleanly to Harmony chat format for GPT-OSS training:

```python
# pip install unsloth
from unsloth_zoo import encode_conversations_with_harmony as enc
from datasets import load_dataset

ds = load_dataset("minhxthanh/Vietnam-History-200K-EN", split="train")

def to_harmony(example):
    return {"input_ids": enc(example["messages"])["input_ids"]}

ds_tok = ds.map(to_harmony, remove_columns=ds.column_names)
```

Use `ds_tok` directly in your SFT trainer.

---

## ğŸ“¦ Shards & sizes

* Each HF dataset provides a single `train` split with the indicated size (e.g., **500k**, **200k**, **100k**, â€¦).
* The 500K releases may be internally sharded for easier hosting; loading through ğŸ¤— Datasets handles this automatically.

---

## ğŸ” License

Each dataset page declares an **MIT** license (check the HF sidebar for the authoritative license for that dataset). Please attribute the dataset URLs when publishing models trained on them.

---

## ğŸ¤ Contributing

* Found an error or want to add more prompts? Open an issue or PR.
* **If this project is useful, please give it a â­ on GitHub and â¤ï¸ Like on the HF dataset page.**

---

## âœï¸ Author

* Hugging Face: [https://huggingface.co/minhxthanh](https://huggingface.co/minhxthanh)
* Model example: `minhxthanh/DeepSeek-R1-Distill-Llama-8B-VN-History` (VN-history-focused 8B model)
