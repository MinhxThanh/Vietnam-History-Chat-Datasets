# Vietnam History Chat Datasets (VI & EN)

Synthetic, instruction-style **chat datasets** about **Vietnamese history (905–2025)** for training and evaluating reasoning-capable chat models (GPT-OSS/Harmony, TRL, etc.).  
Each sample follows a ShareGPT/ChatML-like `messages` schema with optional assistant reasoning in an `analysis` channel and a concise reply in `final`.

> If this project helps you, please **⭐ star** the repo and **❤️ Like** the dataset on Hugging Face!

---

## ⚠️ Disclaimer

**Dataset collection by AI from public source so it can make mistakes.**  
This dataset was collected/generated by AI from public sources and may contain errors or omissions. Please verify and curate before production use.

*Tiếng Việt:* **Bộ dữ liệu được thu thập/tạo bởi AI từ nguồn công khai nên có thể có sai sót.** Hãy kiểm chứng trước khi dùng cho mục đích sản xuất.

---

## 📚 Available datasets (Hugging Face)

- **500K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-500K-Vi  
- **500K (EN):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-500K-En  
- **200K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-200K-Vi  
- **200K (EN):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-200K-EN  
- **100K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-100K_Vi  
- **100K (EN):** https://huggingface.co/datasets/minhxthanh/VietNam-History-100K_EN  
- **50K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-50K  
- **25K (VI):** https://huggingface.co/datasets/minhxthanh/VietNam-History-25K  
- **15K (VI):** https://huggingface.co/datasets/minhxthanh/Vietnam-History-15k

> See the author profile for activity and updates: https://huggingface.co/minhxthanh. :contentReference[oaicite:1]{index=1}

---

## 🧠 Content coverage

From **Khúc/Ngô (905)** → **Đinh – Tiền Lê – Lý – Trần – Hồ – Minh thuộc – Lê sơ – Mạc – Lê trung hưng (Trịnh–Nguyễn) – Tây Sơn – Nguyễn – thời Pháp thuộc – 1945–1975 – Đổi Mới – hội nhập – đương đại (đến 2025)**.  
Prompt styles include **year-based**, **event summaries**, **person-focused**, **why/how causality**, and **context → developments → outcome**.

---

## 🗂️ Data schema

Each row is a JSON object with a single `messages` list:

```json
{
  "messages": [
    {"role": "system", "content": "You are a Vietnam history assistant. Answer concisely."},
    {"role": "user", "content": "What happened in 938?"},
    {"role": "assistant", "channel": "analysis", "content": "Identify the key event..."},
    {"role": "assistant", "channel": "final", "content": "In 938, the Battle of Bạch Đằng... ended Chinese rule."}
  ]
}
````

* `role` ∈ {`system`, `user`, `assistant`}.
* `content`: string.
* Optional `channel` for assistant:

  * `analysis` → chain-of-thought / reasoning (present in most samples).
  * `final` → short answer shown to the user.
* A minority of records are **final-only** (no `analysis`) to balance concise vs. reasoning behavior.

### VI example

```json
{
  "messages": [
    {"role":"system","content":"Bạn là trợ lý lịch sử Việt Nam."},
    {"role":"user","content":"Tóm tắt Trận Bạch Đằng (1288)."},
    {"role":"assistant","channel":"analysis","content":"Xác định bối cảnh kháng Nguyên lần 3..."},
    {"role":"assistant","channel":"final","content":"Năm 1288, Trần Hưng Đạo nhử địch vào bãi cọc trên sông Bạch Đằng và tiêu diệt thủy quân Nguyên."}
  ]
}
```

---

## 🚀 Quick start (🤗 Datasets)

```python
from datasets import load_dataset

ds = load_dataset("minhxthanh/Vietnam-History-500K-Vi", split="train")
print(ds[0]["messages"][0]["role"], ":", ds[0]["messages"][0]["content"])
```

*Tip:* Large splits (e.g., 500K) may stream/convert to Parquet on first load.

---

## 🦥 Harmony / GPT-OSS (Unsloth) workflow

These datasets map cleanly to Harmony chat format for GPT-OSS training:

```python
# pip install unsloth
from unsloth_zoo import encode_conversations_with_harmony as enc
from datasets import load_dataset

ds = load_dataset("minhxthanh/Vietnam-History-200K-EN", split="train")

def to_harmony(example):
    return {"input_ids": enc(example["messages"])["input_ids"]}

ds_tok = ds.map(to_harmony, remove_columns=ds.column_names)
```

Use `ds_tok` directly in your SFT trainer.

---

## 📦 Shards & sizes

* Each HF dataset provides a single `train` split with the indicated size (e.g., **500k**, **200k**, **100k**, …).
* The 500K releases may be internally sharded for easier hosting; loading through 🤗 Datasets handles this automatically.

---

## 🔐 License

Each dataset page declares an **MIT** license (check the HF sidebar for the authoritative license for that dataset). Please attribute the dataset URLs when publishing models trained on them.

---

## 🤝 Contributing

* Found an error or want to add more prompts? Open an issue or PR.
* **If this project is useful, please give it a ⭐ on GitHub and ❤️ Like on the HF dataset page.**

---

## ✍️ Author

* Hugging Face: [https://huggingface.co/minhxthanh](https://huggingface.co/minhxthanh)
* Model example: `minhxthanh/DeepSeek-R1-Distill-Llama-8B-VN-History` (VN-history-focused 8B model)
